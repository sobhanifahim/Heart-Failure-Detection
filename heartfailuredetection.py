# -*- coding: utf-8 -*-
"""HeartFailureDetection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fNEczHICEYGjBBTAW5XjfI4iMRC8KFrr
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np

from sklearn import tree
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.tree import plot_tree

import collections
from PIL import Image
from sklearn.tree import export_graphviz
from IPython.display import Image
from sklearn.tree import export_graphviz
from sklearn.metrics import accuracy_score
import pydotplus

from matplotlib import pyplot as plt
import seaborn as sns
import graphviz
import pydotplus
import io

from scipy import misc
# %matplotlib inline

from google.colab import drive
drive.mount('/content/drive')

data=pd.read_csv('/content/drive/MyDrive/heart.csv')

data.head(4)

X = pd.get_dummies(data.drop('HeartDisease',axis=1),drop_first=True)
y = data['HeartDisease']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=101)
print(len(X_train))
print(len(X_test))

dt = DecisionTreeClassifier()

dt.fit(X_train,y_train)

decision_tree=tree.export_graphviz(dt,out_file='tree.dot',feature_names=X_train.columns,max_depth=5,filled=True)

!dot -Tpng tree.dot -o tree.png

image=plt.imread('tree.png')
plt.figure(figsize=(200,500))
plt.imshow(image)

y_pred=dt.predict(X_test)

y_pred

score=accuracy_score(y_test,y_pred)*100
print("Accuracy using decision tree: ", round(score,1),"%")

from sklearn.ensemble import RandomForestClassifier

dt= RandomForestClassifier (n_estimators=10, max_features="auto", random_state=101)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=101)
print(len(X_train))
print(len(X_test))

dt.fit(X_train,y_train)

y_pred=dt.predict(X_test)

score=accuracy_score(y_test,y_pred)*100
print("Accuracy using random forest: ", round(score,1),"%")

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap
from sklearn import neighbors, datasets

dt = KNeighborsClassifier(n_neighbors=100)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=101)
print(len(X_train))
print(len(X_test))

dt.fit(X_train,y_train)

y_pred=dt.predict(X_test)

score=accuracy_score(y_test,y_pred)*100
print("Accuracy using KNeighbours: ", round(score,1),"%")

from sklearn.neural_network import MLPClassifier

dt = MLPClassifier(alpha=1e-6,hidden_layer_sizes=(50, 25), random_state=1)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=101)
print(len(X_train))
print(len(X_test))

dt.fit(X_train,y_train)

y_pred=dt.predict(X_test)

score=accuracy_score(y_test,y_pred)*100
print("Accuracy using MLP Neural Network: ", round(score,1),"%")

from sklearn.naive_bayes import GaussianNB

dt = GaussianNB()

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=101)
print(len(X_train))
print(len(X_test))

dt.fit(X_train,y_train)

y_pred=dt.predict(X_test)

score=accuracy_score(y_test,y_pred)*100
print("Accuracy using Naive Bayes: ", round(score,1),"%")

from sklearn.svm import SVC

dt = SVC()

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=101)
print(len(X_train))
print(len(X_test))

dt.fit(X_train,y_train)

y_pred=dt.predict(X_test)

score=accuracy_score(y_test,y_pred)*100
print("Accuracy using SVM: ", round(score,1),"%")

from sklearn.linear_model import LogisticRegression

dt = LogisticRegression(random_state=10)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=101)
print(len(X_train))
print(len(X_test))

dt.fit(X_train,y_train)

y_pred=dt.predict(X_test)

score=accuracy_score(y_test,y_pred)*100
print("Accuracy using Logistic Regression: ", round(score,1),"%")

from sklearn.linear_model import SGDClassifier

dt = SGDClassifier(max_iter=100, tol=1e-9)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=101)
print(len(X_train))
print(len(X_test))

dt.fit(X_train,y_train)

y_pred=dt.predict(X_test)

score=accuracy_score(y_test,y_pred)*100
print("Accuracy using SGD: ", round(score,1),"%")